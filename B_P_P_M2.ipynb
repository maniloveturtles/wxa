{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1210d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# =========================\n",
    "# COMP3010 BLEVE — FULL NOTEBOOK PIPELINE (Dev Rewrite)\n",
    "# Key decisions:\n",
    "# - Train on log1p(y) (stability + better relative error behavior)\n",
    "# - Predict with expm1\n",
    "# - Leakage-safe GroupKFold using scenario-level grouping (exclude sensor-specific fields)\n",
    "# - Robust encoding + imputation\n",
    "# - Stable MAPE implementation + group sanity checks\n",
    "# =========================\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CELL 0 — CONFIG\n",
    "# -------------------------\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEED = 42\n",
    "N_SPLITS = 5\n",
    "\n",
    "DATA_DIR = \".\"  # change if needed\n",
    "TRAIN_PATH  = os.path.join(DATA_DIR, \"train.csv\")\n",
    "TEST_PATH   = os.path.join(DATA_DIR, \"test.csv\")\n",
    "SAMPLE_PATH = os.path.join(DATA_DIR, \"sample_prediction.csv\")\n",
    "\n",
    "OUT_PATH = \"prediction.csv\"\n",
    "\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96c957b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir: c:\\Users\\samzt\\OneDrive\\Documents\\COMP3010_BLEVE_Project\\notebook\n",
      "Files in DATA_DIR: ['sample_prediction.csv', 'test.csv', 'train.csv']\n",
      "Loaded shapes:\n",
      "train : (10050, 25)\n",
      "test  : (3203, 24)\n",
      "sample: (3203, 2)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CELL 2 — LOAD DATA (LOCAL: ../data folder)\n",
    "# =========================\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in DATA_DIR:\", os.listdir(DATA_DIR))\n",
    "\n",
    "train = pd.read_csv(f\"{DATA_DIR}/train.csv\")\n",
    "test = pd.read_csv(f\"{DATA_DIR}/test.csv\")\n",
    "sample = pd.read_csv(f\"{DATA_DIR}/sample_prediction.csv\")\n",
    "\n",
    "print(\"Loaded shapes:\")\n",
    "print(\"train :\", train.shape)\n",
    "print(\"test  :\", test.shape)\n",
    "print(\"sample:\", sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37bb9129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After clean: (10000, 25) (3203, 23)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# CELL 2 — CLEAN + NORMALIZE COLUMN NAMES\n",
    "# -------------------------\n",
    "def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def drop_index_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in [\"Unnamed: 0\", \"index\"]:\n",
    "        if c in df.columns and df[c].nunique() == len(df):\n",
    "            df = df.drop(columns=[c])\n",
    "    return df\n",
    "\n",
    "def normalize_cats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in [\"Status\", \"Sensor Position Side\"]:\n",
    "        if c in df.columns:\n",
    "            s = df[c].astype(\"string\").str.strip().str.lower()\n",
    "            s = s.replace({\"nan\": pd.NA, \"none\": pd.NA, \"\": pd.NA})\n",
    "            df[c] = s\n",
    "    return df\n",
    "\n",
    "train = normalize_cols(train)\n",
    "test  = normalize_cols(test)\n",
    "\n",
    "train = drop_index_cols(train)\n",
    "test  = drop_index_cols(test)\n",
    "\n",
    "train = normalize_cats(train)\n",
    "test  = normalize_cats(test)\n",
    "\n",
    "train = train.drop_duplicates()\n",
    "print(\"After clean:\", train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93079d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TARGET: Target_Pressure_(bar)\n",
      "FE shapes: (10000, 29) (3203, 27)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# CELL 3 — FEATURE ENGINEERING (safe + consistent)\n",
    "# Also renames columns to avoid whitespace warnings in LightGBM\n",
    "# -------------------------\n",
    "def safe_div(a, b):\n",
    "    b = np.where(b == 0, np.nan, b)\n",
    "    return a / b\n",
    "\n",
    "def fe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # rename spaces -> underscores once for the whole pipeline\n",
    "    df.columns = df.columns.str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "\n",
    "    def has(cols): return all(c in df.columns for c in cols)\n",
    "\n",
    "    # tank volume + shape\n",
    "    if has([\"Tank_Width_(m)\", \"Tank_Length_(m)\", \"Tank_Height_(m)\"]):\n",
    "        W = df[\"Tank_Width_(m)\"].astype(float)\n",
    "        L = df[\"Tank_Length_(m)\"].astype(float)\n",
    "        H = df[\"Tank_Height_(m)\"].astype(float)\n",
    "        df[\"tank_vol\"] = W * L * H\n",
    "        df[\"tank_w_over_l\"] = safe_div(W, L)\n",
    "\n",
    "    # vapour fraction\n",
    "    if has([\"Vapour_Height_(m)\", \"Tank_Height_(m)\"]):\n",
    "        df[\"vapour_height_frac\"] = safe_div(df[\"Vapour_Height_(m)\"].astype(float),\n",
    "                                            df[\"Tank_Height_(m)\"].astype(float))\n",
    "\n",
    "    # obstacle area\n",
    "    if has([\"Obstacle_Width_(m)\", \"Obstacle_Height_(m)\"]):\n",
    "        df[\"obs_area\"] = df[\"Obstacle_Width_(m)\"].astype(float) * df[\"Obstacle_Height_(m)\"].astype(float)\n",
    "\n",
    "    # sensor radius\n",
    "    if has([\"Sensor_Position_x_(m)\", \"Sensor_Position_y_(m)\", \"Sensor_Position_z_(m)\"]):\n",
    "        x = df[\"Sensor_Position_x_(m)\"].astype(float)\n",
    "        y = df[\"Sensor_Position_y_(m)\"].astype(float)\n",
    "        z = df[\"Sensor_Position_z_(m)\"].astype(float)\n",
    "        df[\"sensor_r\"] = np.sqrt(x*x + y*y + z*z)\n",
    "\n",
    "    # sensor_r / obstacle distance\n",
    "    if has([\"sensor_r\", \"Obstacle_Distance_to_BLEVE_(m)\"]):\n",
    "        df[\"sensor_r_over_obsdist\"] = safe_div(df[\"sensor_r\"].astype(float),\n",
    "                                               df[\"Obstacle_Distance_to_BLEVE_(m)\"].astype(float))\n",
    "\n",
    "    # hard safety\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    return df\n",
    "\n",
    "train_fe = fe(train)\n",
    "test_fe  = fe(test)\n",
    "\n",
    "# target auto-detect (since we renamed spaces->underscores)\n",
    "if \"Target_Pressure_(bar)\" in train_fe.columns:\n",
    "    TARGET = \"Target_Pressure_(bar)\"\n",
    "elif \"Target Pressure (bar)\" in train_fe.columns:\n",
    "    TARGET = \"Target Pressure (bar)\"\n",
    "else:\n",
    "    raise KeyError(\"Target column not found after FE.\")\n",
    "\n",
    "print(\"Using TARGET:\", TARGET)\n",
    "print(\"FE shapes:\", train_fe.shape, test_fe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69ae6ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique groups: 10000 rows: 10000\n",
      "group size min/median/max: 1 1.0 1\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# CELL 4 — SCENARIO GROUPS (leakage-safe)\n",
    "# Group key must use ONLY scenario/config variables (exclude sensor fields + target)\n",
    "# -------------------------\n",
    "SENSOR_FIELDS = [\n",
    "    \"Sensor_ID\",\n",
    "    \"Sensor_Position_Side\",\n",
    "    \"Sensor_Position_x_(m)\",\n",
    "    \"Sensor_Position_y_(m)\",\n",
    "    \"Sensor_Position_z_(m)\",\n",
    "    \"sensor_r\",\n",
    "    \"sensor_r_over_obsdist\",\n",
    "]\n",
    "\n",
    "exclude_for_group = set(SENSOR_FIELDS + [TARGET])\n",
    "\n",
    "scenario_cols = [c for c in train_fe.columns if c not in exclude_for_group]\n",
    "\n",
    "gdf = train_fe[scenario_cols].copy()\n",
    "\n",
    "# stabilize numeric representation\n",
    "for c in gdf.columns:\n",
    "    if pd.api.types.is_numeric_dtype(gdf[c]):\n",
    "        gdf[c] = gdf[c].round(6)\n",
    "    gdf[c] = gdf[c].astype(str)\n",
    "\n",
    "groups = pd.util.hash_pandas_object(gdf, index=False).astype(\"int64\").to_numpy()\n",
    "\n",
    "u, cnt = np.unique(groups, return_counts=True)\n",
    "print(\"unique groups:\", len(u), \"rows:\", len(groups))\n",
    "print(\"group size min/median/max:\", int(cnt.min()), float(np.median(cnt)), int(cnt.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dafe793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shapes: (10000, 27) (3203, 27)\n",
      "encoded obj cols: 2 dropped constants: 0\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# CELL 5 — BUILD X/y (align + encode + constants)\n",
    "# Train on log1p(y)\n",
    "# -------------------------\n",
    "y = train_fe[TARGET].astype(float).to_numpy()\n",
    "y = np.clip(y, 1e-6, None)\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "X_train = train_fe.drop(columns=[TARGET]).copy()\n",
    "X_test  = test_fe.copy()\n",
    "\n",
    "# align columns\n",
    "common = X_train.columns.intersection(X_test.columns)\n",
    "X_train = X_train[common].copy()\n",
    "X_test  = X_test[common].copy()\n",
    "\n",
    "# encode any object/string cols\n",
    "obj_cols = X_train.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "for c in obj_cols:\n",
    "    X_train[c] = X_train[c].fillna(\"NA\").astype(str).str.strip().str.lower()\n",
    "    X_test[c]  = X_test[c].fillna(\"NA\").astype(str).str.strip().str.lower()\n",
    "\n",
    "    cats = pd.Index(pd.concat([X_train[c], X_test[c]], axis=0).unique())\n",
    "    mapper = {k: i for i, k in enumerate(cats)}\n",
    "    X_train[c] = X_train[c].map(mapper).astype(\"int32\")\n",
    "    X_test[c]  = X_test[c].map(mapper).astype(\"int32\")\n",
    "\n",
    "# final safety\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "X_test  = X_test.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# drop constant columns\n",
    "const_cols = [c for c in X_train.columns if X_train[c].nunique(dropna=False) <= 1]\n",
    "if const_cols:\n",
    "    X_train = X_train.drop(columns=const_cols)\n",
    "    X_test  = X_test.drop(columns=const_cols)\n",
    "\n",
    "print(\"X shapes:\", X_train.shape, X_test.shape)\n",
    "print(\"encoded obj cols:\", len(obj_cols), \"dropped constants:\", len(const_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0d8f2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Info] Total Bins 3065\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 27\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Info] Start training from score 0.267985\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1944]\tvalid_0's l1: 0.0223656\tvalid_0's l2: 0.00147028\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "Fold 1 | stable MAPE: 99.92645 | best_iter: 1944\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Info] Total Bins 3058\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 27\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Info] Start training from score 0.264346\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19394]\tvalid_0's l1: 0.0241156\tvalid_0's l2: 0.00187626\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "Fold 2 | stable MAPE: 67.30093 | best_iter: 19394\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Info] Total Bins 3063\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 27\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Info] Start training from score 0.268117\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19344]\tvalid_0's l1: 0.0245538\tvalid_0's l2: 0.00195475\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "Fold 3 | stable MAPE: 44.54763 | best_iter: 19344\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Info] Total Bins 3067\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 27\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Info] Start training from score 0.270956\n",
      "Training until validation scores don't improve for 500 rounds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m ytr, yva = y_log[tr], y_log[va]\n\u001b[32m     39\u001b[39m model = LGBMRegressor(**params)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXva\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myva\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ml1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m pred_log = model.predict(Xva)\n\u001b[32m     48\u001b[39m pred = np.expm1(pred_log)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightgbm\\sklearn.py:1398\u001b[39m, in \u001b[36mLGBMRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1383\u001b[39m     X: _LGBM_ScikitMatrixLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1395\u001b[39m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1396\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLGBMRegressor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1397\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightgbm\\sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightgbm\\engine.py:322\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[32m    311\u001b[39m     cb(\n\u001b[32m    312\u001b[39m         callback.CallbackEnv(\n\u001b[32m    313\u001b[39m             model=booster,\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m         )\n\u001b[32m    320\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mbooster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] = []\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\lightgbm\\basic.py:4155\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, train_set, fobj)\u001b[39m\n\u001b[32m   4152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__set_objective_to_none:\n\u001b[32m   4153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[33m\"\u001b[39m\u001b[33mCannot update due to null objective function.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4154\u001b[39m _safe_call(\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4159\u001b[39m )\n\u001b[32m   4160\u001b[39m \u001b[38;5;28mself\u001b[39m.__is_predicted_cur_iter = [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.__num_dataset)]\n\u001b[32m   4161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished.value == \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# CELL 6 — CV (GroupKFold) + LightGBM (stronger splits) + stable MAPE\n",
    "# -------------------------\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "\n",
    "def stable_mape(y_true, y_pred, eps=1e-6):\n",
    "    y_true = np.clip(np.asarray(y_true, dtype=float), eps, None)\n",
    "    y_pred = np.clip(np.asarray(y_pred, dtype=float), eps, None)\n",
    "    return float(np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "\n",
    "params = dict(\n",
    "    objective=\"regression\",\n",
    "    n_estimators=30000,\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=256,\n",
    "    max_depth=-1,\n",
    "    min_data_in_leaf=5,\n",
    "    subsample=0.85,\n",
    "    subsample_freq=1,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    "    force_col_wise=True,\n",
    ")\n",
    "\n",
    "gkf = GroupKFold(n_splits=N_SPLITS)\n",
    "fold_scores = []\n",
    "oof = np.zeros(len(X_train), dtype=float)\n",
    "\n",
    "for fold, (tr, va) in enumerate(gkf.split(X_train, y_log, groups), 1):\n",
    "    Xtr, Xva = X_train.iloc[tr], X_train.iloc[va]\n",
    "    ytr, yva = y_log[tr], y_log[va]\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "    model.fit(\n",
    "        Xtr, ytr,\n",
    "        eval_set=[(Xva, yva)],\n",
    "        eval_metric=\"l1\",\n",
    "        callbacks=[lgb.early_stopping(500), lgb.log_evaluation(0)]\n",
    "    )\n",
    "\n",
    "    pred_log = model.predict(Xva)\n",
    "    pred = np.expm1(pred_log)\n",
    "    pred = np.clip(pred, 1e-6, None)\n",
    "\n",
    "    m = stable_mape(y[va], pred, eps=1e-6)\n",
    "    fold_scores.append(m)\n",
    "    oof[va] = pred\n",
    "\n",
    "    print(f\"Fold {fold} | stable MAPE: {m:.5f} | best_iter: {model.best_iteration_}\")\n",
    "\n",
    "print(\"CV stable MAPE mean:\", float(np.mean(fold_scores)), \"std:\", float(np.std(fold_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab1f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "[LightGBM] [Info] Total Bins 3066\n",
      "[LightGBM] [Info] Number of data points in the train set: 10000, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 0.267983\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "Saved: prediction.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Target Pressure (bar)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.093965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.094430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.095009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.079920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.072371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Target Pressure (bar)\n",
       "0   0               0.093965\n",
       "1   1               0.094430\n",
       "2   2               0.095009\n",
       "3   3               0.079920\n",
       "4   4               0.072371"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# CELL 7 — TRAIN FULL + PREDICT TEST + SAVE\n",
    "# -------------------------\n",
    "final = LGBMRegressor(**params)\n",
    "final.fit(X_train, y_log, eval_metric=\"l1\")\n",
    "\n",
    "test_pred_log = final.predict(X_test)\n",
    "test_pred = np.expm1(test_pred_log)\n",
    "test_pred = np.clip(test_pred, 1e-6, None)\n",
    "\n",
    "sub = sample.copy()\n",
    "sub.iloc[:, 1] = test_pred\n",
    "sub.to_csv(OUT_PATH, index=False)\n",
    "\n",
    "print(\"Saved:\", OUT_PATH)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
